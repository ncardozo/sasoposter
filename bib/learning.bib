@inproceedings{Cardozo2017,
 author = {Cardozo, Nicol\'{a}s and Dusparic, Ivana and Castro, Jorge H.},
 title = {Peace {COrP}: Learning to solve conflicts between contexts},
 booktitle = {Int. Workshop on Context-Oriented Programming},
 series = {COP'17},
 year = {2017},
 address = {New York, NY, USA},
} 

%basic rl
@article{Watkins92,
        author = {Watkins, Christopher  J. C. H.  and Dayan, Peter},
	journal = {Machine Learning},
	month = {May},
year={1992},
	number = {3},
   volume = {8},
	OPTpages = {279--292},
	title = {Technical Note: Q-Learning},

}

@article{Tesauro2007,
        author = {Tesauro G.},
	journal = {IEEE Internet Computing},
	year={2007},
	number = {1},
   volume = {11},
	OPTpages = {22--30},
	title = {Reinforcement learning in autonomic computing: A manifesto and case studies}

}

@book{Sutton1998,
 author = {Sutton R. S. and Barto A. G. },
 title = {Reinforcement Learning: An Introduction.},
 year = {1998},
  publisher = {Bradford
Book. The MIT Press, Cambridge, Massachusetts}}

@article{dusparic2012TAAS,
  title={Autonomic multi-policy optimization in pervasive systems: Overview and evaluation},
  author={Dusparic, Ivana and Cahill, Vinny},
  journal={TAAS},
  volume={7},
  number={1},
  OPTpages={11},
  year={2012},
  publisher={ACM}
}

% using  macro-actions
@INPROCEEDINGS{Elfwing2004, 
author={S. Elfwing and E. Uchibe and K. Doya and H. I. Christensen}, 
booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
title={Multi-agent reinforcement learning: using macro actions to learn a mating task}, 
year={2004}, 
series = {IROS'04},
volume={4}, 
pages={3164-3169}, 
OPTdoi={10.1109/IROS.2004.1389904}, 
month={Sept}}

% learning macro-actions
@inproceedings{YoshikawaK06,
  author    = {Takeshi Yoshikawa and
               Masahito Kurihara},
  title     = {An Acquiring Method of Macro-Actions in Reinforcement Learning},
  booktitle = {Proceedings of the {IEEE} International Conference on Systems, Man
               and Cybernetics, Taipei, Taiwan, October 8-11, 2006},
  pages     = {4813--4817},
  year      = {2006},
  OPTdoi       = {10.1109/ICSMC.2006.385067}
}

@INPROCEEDINGS{Pickett02,
    author = {Marc Pickett and Andrew G. Barto},
    title = {PolicyBlocks: An Algorithm for Creating Useful Macro-Actions in Reinforcement Learning},
    booktitle = {Int. Conference on Machine Learning},
    year = {2002},
    pages = {506--513},
    publisher = {Morgan Kaufmann}
}

@INPROCEEDINGS{Mcgovern98,
    author = {Amy Mcgovern},
    title = {acQuire-macros: An Algorithm for Automatically Learning Macro-actions},
    booktitle = {In NIPS'98 Workshop on Abstraction and Hierarchy in Reinforcement Learning},
    year = {1998}
}

@inproceedings{Randlov1998,
 author = {Randl{\o}v, Jette},
 title = {Learning Macro-actions in Reinforcement Learning},
 booktitle = {Proceedings of the 11th International Conference on Neural Information Processing Systems},
 series = {NIPS'98},
 year = {1998},
 location = {Denver, CO},
 pages = {1045--1051},
 numpages = {7},
 OPTurl = {http://dl.acm.org/citation.cfm?id=3009055.3009201},
 acmid = {3009201},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 


% benefits of macro-actions

@techreport{McGovernandSutton1998,
 author = {McGovern, Amy and Sutton, Richard S.},
 title = {Macro-Actions in Reinforcement Learning: An Empirica Analysis},
 year = {1998},
 publisher = {University of Massachusetts},
 address = {Amherst, MA, USA},
} 

@article{DurugkarRDM16,
  author    = {Ishan P. Durugkar and
               Clemens Rosenbaum and
               Stefan Dernbach and
               Sridhar Mahadevan},
  title     = {Deep Reinforcement Learning With Macro-Actions},
  journal   = {CoRR},
  volume    = {1606.04615},
  year      = {2016},
  OPTurl       = {http://arxiv.org/abs/1606.04615},
  timestamp = {Fri, 01 Jul 2016 01:00:00 +0200},
  OPTbiburl    = {http://dblp2.uni-trier.de/rec/bib/journals/corr/DurugkarRDM16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

